{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/tweets&sentiment&absoluteprices&topics.csv', index_col=0)\n",
    "final_test_df = pd.read_csv('../data/test_data_tweets&sentiment&topic&absoluteprices.csv', index_col=0).drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26231, 29)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "Word2Vec is the chosen text embedding method for several reasons:\n",
    "* The mapping between the target word to its context word implicitly embeds the sub-linear relationship into the vector space of words, so that relationships like “king:man as queen:woman” can be infered by word vectors.\n",
    "* It is less computationally expensive than deep language models such as GloVe, BERT, ElMo. BERT + transfer learning with BiLSTM was initially chosen for this problem but due to the relatively large dataset and limited computational power, training was extremely slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further process text for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_w2v(paragraph):    \n",
    "    result = list()\n",
    "    for line in nltk.sent_tokenize(paragraph):\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        tokens = [token for token in tokenizer.tokenize(line)]\n",
    "        result.append(tokens) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text_w2v'] = df['cleaned_text'].apply(lambda x: process_text_w2v(x))\n",
    "final_test_df['cleaned_text_w2v'] = final_test_df['cleaned_text'].apply(lambda x: process_text_w2v(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all sentences together to compose the corpus for later usage.\n",
    "df_sentences = [sent for x in df['cleaned_text_w2v'].values.tolist() for sent in x]\n",
    "final_test_df_sentences = [sent for x in final_test_df['cleaned_text_w2v'].values.tolist() for sent in x]\n",
    "\n",
    "sentences = df_sentences + final_test_df_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89c305fcd163488441ac2ac6133678bd973b4419"
   },
   "source": [
    "### Set parameters for word2vec model\n",
    "`min_count` is set to 1 since we would like to obtain the embeddings of all words in our vocabulary for subsequent modelling to work. Normally, `min_count` is set to a larger value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "ad619db82c219d6cb81fad516563feb0c4d474cd"
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=1, \n",
    "                     window=3,\n",
    "                     size=64,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7e9f1bd338f9e15647b5209ffd8fbb131cd7ee5"
   },
   "source": [
    "### Building the Vocabulary Table\n",
    "Digest all the words and filter out the unique words, and doing some basic counts on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "66358ad743e05e17dfbed3899af9c41056143daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.07 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63260d82061abb47db7f2f8b23e07ec629adf5a9"
   },
   "source": [
    "### Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.23 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - start_time) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('../model/word2vec/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "34dd51c7f2f39d016b982ef81e4df576f6b31bcb"
   },
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Word2Vec vectors\n",
    "generate and write the word embedding vectors to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from the model file\n",
    "# w2v_model = Word2Vec.load('../model/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vectors_to_file(df, filename):\n",
    "    \n",
    "    # Store the vectors in a csv file\n",
    "    path = '../model/word2vec/' + filename\n",
    "    \n",
    "    with open(path, 'w+') as word2vec_file:\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            model_vector = (np.mean([w2v_model[token] for token in row['cleaned_text_w2v'][0]], axis=0)).tolist()\n",
    "\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(64))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "\n",
    "            # Check if the line exists else it is vector of zeros\n",
    "            if type(model_vector) is list:  \n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(64)])\n",
    "\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "write_vectors_to_file(df, 'word2vec_train.csv')\n",
    "write_vectors_to_file(final_test_df, 'word2vec_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the word embeddings with other features in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embeddings_train = pd.read_csv('../model/word2vec/word2vec_train.csv')\n",
    "w2v_embeddings_test = pd.read_csv('../model/word2vec/word2vec_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, w2v_embeddings_train], axis=1)\n",
    "final_test_df = pd.concat([final_test_df, w2v_embeddings_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>mention</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Thank you @HerschelWalker! https://t.co/XjlYe8...</td>\n",
       "      <td>thank</td>\n",
       "      <td>2020-09-30 23:45:25</td>\n",
       "      <td>19616</td>\n",
       "      <td>65721</td>\n",
       "      <td>False</td>\n",
       "      <td>1311512518800470016</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@HerschelWalker']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056449</td>\n",
       "      <td>0.303183</td>\n",
       "      <td>0.076234</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.095509</td>\n",
       "      <td>-0.203082</td>\n",
       "      <td>-0.040352</td>\n",
       "      <td>-0.033276</td>\n",
       "      <td>-0.246406</td>\n",
       "      <td>0.033626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @GOPChairwoman: Big news!A Maine court side...</td>\n",
       "      <td>big news maine court side rnc uphold ban ballo...</td>\n",
       "      <td>2020-09-30 23:25:31</td>\n",
       "      <td>29393</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1311507509958471680</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033750</td>\n",
       "      <td>0.029573</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>-0.112900</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.082210</td>\n",
       "      <td>-0.112283</td>\n",
       "      <td>0.068804</td>\n",
       "      <td>-0.176641</td>\n",
       "      <td>0.058202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Thank you Paul! https://t.co/aAk1sfww0d</td>\n",
       "      <td>thank paul</td>\n",
       "      <td>2020-09-30 23:00:33</td>\n",
       "      <td>15992</td>\n",
       "      <td>63294</td>\n",
       "      <td>False</td>\n",
       "      <td>1311501225423073281</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.201051</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.021847</td>\n",
       "      <td>-0.134962</td>\n",
       "      <td>-0.028476</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>-0.294078</td>\n",
       "      <td>0.040799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>100000 DEFECTIVE BALLOTS IN NEW YORK. THEY WAN...</td>\n",
       "      <td>defective ballot new york want replace happen ...</td>\n",
       "      <td>2020-09-30 22:59:02</td>\n",
       "      <td>51445</td>\n",
       "      <td>190750</td>\n",
       "      <td>False</td>\n",
       "      <td>1311500843309387781</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031608</td>\n",
       "      <td>-0.041660</td>\n",
       "      <td>0.075459</td>\n",
       "      <td>-0.142272</td>\n",
       "      <td>-0.035155</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>-0.070449</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>-0.224101</td>\n",
       "      <td>0.003555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>In just 3 and a half years we have secured Ame...</td>\n",
       "      <td>half years secure americas border rebuild awes...</td>\n",
       "      <td>2020-09-30 22:51:05</td>\n",
       "      <td>18885</td>\n",
       "      <td>70838</td>\n",
       "      <td>False</td>\n",
       "      <td>1311498845860196355</td>\n",
       "      <td>['#MAGA']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063390</td>\n",
       "      <td>0.071681</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>-0.082486</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>-0.096789</td>\n",
       "      <td>-0.039431</td>\n",
       "      <td>0.056586</td>\n",
       "      <td>-0.196989</td>\n",
       "      <td>0.061467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  Thank you @HerschelWalker! https://t.co/XjlYe8...   \n",
       "1  Twitter for iPhone  RT @GOPChairwoman: Big news!A Maine court side...   \n",
       "2  Twitter for iPhone            Thank you Paul! https://t.co/aAk1sfww0d   \n",
       "3  Twitter for iPhone  100000 DEFECTIVE BALLOTS IN NEW YORK. THEY WAN...   \n",
       "4  Twitter for iPhone  In just 3 and a half years we have secured Ame...   \n",
       "\n",
       "                                        cleaned_text           created_at  \\\n",
       "0                                              thank  2020-09-30 23:45:25   \n",
       "1  big news maine court side rnc uphold ban ballo...  2020-09-30 23:25:31   \n",
       "2                                         thank paul  2020-09-30 23:00:33   \n",
       "3  defective ballot new york want replace happen ...  2020-09-30 22:59:02   \n",
       "4  half years secure americas border rebuild awes...  2020-09-30 22:51:05   \n",
       "\n",
       "   retweet_count  favorite_count  is_retweet               id_str    hashtag  \\\n",
       "0          19616           65721       False  1311512518800470016         []   \n",
       "1          29393               0        True  1311507509958471680         []   \n",
       "2          15992           63294       False  1311501225423073281         []   \n",
       "3          51445          190750       False  1311500843309387781         []   \n",
       "4          18885           70838       False  1311498845860196355  ['#MAGA']   \n",
       "\n",
       "               mention  ...        54        55        56        57        58  \\\n",
       "0  ['@HerschelWalker']  ...  0.056449  0.303183  0.076234  0.011941  0.095509   \n",
       "1                   []  ... -0.033750  0.029573  0.057895 -0.112900  0.000638   \n",
       "2                   []  ...  0.071690  0.201051  0.034127 -0.064866 -0.021847   \n",
       "3                   []  ... -0.031608 -0.041660  0.075459 -0.142272 -0.035155   \n",
       "4                   []  ... -0.063390  0.071681  0.035991 -0.082486  0.025676   \n",
       "\n",
       "         59        60        61        62        63  \n",
       "0 -0.203082 -0.040352 -0.033276 -0.246406  0.033626  \n",
       "1 -0.082210 -0.112283  0.068804 -0.176641  0.058202  \n",
       "2 -0.134962 -0.028476  0.004518 -0.294078  0.040799  \n",
       "3 -0.014330 -0.070449  0.004803 -0.224101  0.003555  \n",
       "4 -0.096789 -0.039431  0.056586 -0.196989  0.061467  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>mention</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I won the debate big based on compilation of p...</td>\n",
       "      <td>debate big base compilation poll etc thank</td>\n",
       "      <td>2020-10-01 11:14:28</td>\n",
       "      <td>44961</td>\n",
       "      <td>337926</td>\n",
       "      <td>False</td>\n",
       "      <td>1311685923097260034</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077325</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>-0.128470</td>\n",
       "      <td>-0.038628</td>\n",
       "      <td>-0.079148</td>\n",
       "      <td>-0.023730</td>\n",
       "      <td>-0.231218</td>\n",
       "      <td>0.100820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Why would I allow the Debate Commission to cha...</td>\n",
       "      <td>would allow debate commission change rule seco...</td>\n",
       "      <td>2020-10-01 14:15:26</td>\n",
       "      <td>41516</td>\n",
       "      <td>247053</td>\n",
       "      <td>False</td>\n",
       "      <td>1311731462589292544</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022978</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.105070</td>\n",
       "      <td>-0.088523</td>\n",
       "      <td>-0.065970</td>\n",
       "      <td>-0.024742</td>\n",
       "      <td>-0.055147</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>-0.172681</td>\n",
       "      <td>0.104142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>THANK YOU! #MAGA https://t.co/nGfbRmfmG7</td>\n",
       "      <td>thank maga</td>\n",
       "      <td>2020-10-01 15:09:17</td>\n",
       "      <td>18014</td>\n",
       "      <td>63744</td>\n",
       "      <td>False</td>\n",
       "      <td>1311745016780460033</td>\n",
       "      <td>['#MAGA']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022568</td>\n",
       "      <td>0.298728</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.070448</td>\n",
       "      <td>0.074991</td>\n",
       "      <td>-0.213843</td>\n",
       "      <td>-0.072632</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>-0.230358</td>\n",
       "      <td>0.095514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Exclusive Excerpt--Lewandowski &amp;amp; Bossie: ‘...</td>\n",
       "      <td>exclusive excerpt lewandowski amp bossie trump...</td>\n",
       "      <td>2020-10-01 17:12:22</td>\n",
       "      <td>6407</td>\n",
       "      <td>23646</td>\n",
       "      <td>False</td>\n",
       "      <td>1311775992847818754</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@BreitbartNews']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>0.078566</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>-0.041604</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>-0.165470</td>\n",
       "      <td>-0.036430</td>\n",
       "      <td>0.098156</td>\n",
       "      <td>-0.152624</td>\n",
       "      <td>0.033352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @GreggJarrett: Corrupt Comey conveniently c...</td>\n",
       "      <td>corrupt comey conveniently claim no memory par...</td>\n",
       "      <td>2020-10-01 17:14:12</td>\n",
       "      <td>4755</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1311776453717942272</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060734</td>\n",
       "      <td>-0.047410</td>\n",
       "      <td>0.050447</td>\n",
       "      <td>-0.125226</td>\n",
       "      <td>-0.044856</td>\n",
       "      <td>-0.033562</td>\n",
       "      <td>-0.058906</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>-0.164322</td>\n",
       "      <td>-0.070981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  I won the debate big based on compilation of p...   \n",
       "1  Twitter for iPhone  Why would I allow the Debate Commission to cha...   \n",
       "2  Twitter for iPhone           THANK YOU! #MAGA https://t.co/nGfbRmfmG7   \n",
       "3  Twitter for iPhone  Exclusive Excerpt--Lewandowski &amp; Bossie: ‘...   \n",
       "4  Twitter for iPhone  RT @GreggJarrett: Corrupt Comey conveniently c...   \n",
       "\n",
       "                                        cleaned_text           created_at  \\\n",
       "0         debate big base compilation poll etc thank  2020-10-01 11:14:28   \n",
       "1  would allow debate commission change rule seco...  2020-10-01 14:15:26   \n",
       "2                                         thank maga  2020-10-01 15:09:17   \n",
       "3  exclusive excerpt lewandowski amp bossie trump...  2020-10-01 17:12:22   \n",
       "4  corrupt comey conveniently claim no memory par...  2020-10-01 17:14:12   \n",
       "\n",
       "   retweet_count  favorite_count  is_retweet               id_str    hashtag  \\\n",
       "0          44961          337926       False  1311685923097260034         []   \n",
       "1          41516          247053       False  1311731462589292544         []   \n",
       "2          18014           63744       False  1311745016780460033  ['#MAGA']   \n",
       "3           6407           23646       False  1311775992847818754         []   \n",
       "4           4755               0        True  1311776453717942272         []   \n",
       "\n",
       "              mention  ...        54        55        56        57        58  \\\n",
       "0                  []  ...  0.077325  0.078596  0.117261 -0.024885 -0.128470   \n",
       "1                  []  ... -0.022978  0.015267  0.105070 -0.088523 -0.065970   \n",
       "2                  []  ... -0.022568  0.298728  0.066300  0.070448  0.074991   \n",
       "3  ['@BreitbartNews']  ...  0.083277  0.078566  0.054099 -0.041604  0.008532   \n",
       "4                  []  ...  0.060734 -0.047410  0.050447 -0.125226 -0.044856   \n",
       "\n",
       "         59        60        61        62        63  \n",
       "0 -0.038628 -0.079148 -0.023730 -0.231218  0.100820  \n",
       "1 -0.024742 -0.055147  0.007281 -0.172681  0.104142  \n",
       "2 -0.213843 -0.072632 -0.007993 -0.230358  0.095514  \n",
       "3 -0.165470 -0.036430  0.098156 -0.152624  0.033352  \n",
       "4 -0.033562 -0.058906  0.115426 -0.164322 -0.070981  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
